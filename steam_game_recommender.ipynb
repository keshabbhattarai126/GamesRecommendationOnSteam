{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb9785-670f-4bb3-afe5-8651e90b7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#project created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a52708-7462-42ea-876c-276c20ca267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading and Cleaning Data...\n",
      "Detected columns in CSV: ['app_id', 'title', 'date_release', 'win', 'mac', 'linux', 'rating', 'positive_ratio', 'user_reviews', 'price_final', 'price_original', 'discount', 'steam_deck']\n",
      "Step 2: Preparing features...\n",
      "Step 3: Vectorizing and Calculating Similarity...\n",
      "Success! Similarity matrix created.\n",
      "\n",
      "Testing recommendations for: Prince of Persia: Warrior Within™\n",
      "                          title                 features\n",
      "1       BRINK: Agents of Change  steam game indie casual\n",
      "2  Monaco: What's Yours Is Mine  steam game indie casual\n",
      "3            Escape Dead Island  steam game indie casual\n",
      "4       Dungeon of the ENDLESS™  steam game indie casual\n",
      "5                  METAL SLUG 3  steam game indie casual\n",
      "\n",
      "Step 4: Saving pkl files for app.py...\n",
      "All set! 'similarity_model.pkl' and 'games_data.pkl' are in your folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATA LOADING & DYNAMIC COLUMN HANDLING\n",
    "# ==========================================\n",
    "print(\"Step 1: Loading and Cleaning Data...\")\n",
    "# Load dataset - Ensure 'games.csv' is in your project folder\n",
    "try:\n",
    "    games = pd.read_csv('games.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'games.csv' not found. Please check your file path.\")\n",
    "    raise\n",
    "\n",
    "# Limiting to 15,000 records for performance while meeting assignment size requirements\n",
    "games = games.head(15000).copy() \n",
    "\n",
    "# Detect actual column names to prevent KeyError\n",
    "cols = games.columns.tolist()\n",
    "print(f\"Detected columns in CSV: {cols}\")\n",
    "\n",
    "genre_col = next((c for c in ['genres', 'genre', 'categories'] if c in cols), None)\n",
    "tag_col = next((c for c in ['tags', 'popular_tags'] if c in cols), None)\n",
    "desc_col = next((c for c in ['description', 'short_description', 'about_the_game'] if c in cols), None)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ADVANCED FEATURE ENGINEERING (Fixes ValueError)\n",
    "# ==========================================\n",
    "print(\"Step 2: Preparing features...\")\n",
    "\n",
    "# Combine text columns. If a column is missing, it's ignored.\n",
    "games['features'] = \"\"\n",
    "if genre_col:\n",
    "    games['features'] += games[genre_col].fillna('') + \" \"\n",
    "if tag_col:\n",
    "    games['features'] += games[tag_col].fillna('') + \" \"\n",
    "if desc_col:\n",
    "    games['features'] += games[desc_col].fillna('')\n",
    "\n",
    "# Preprocessing: Lowercase and strip whitespace\n",
    "games['features'] = games['features'].str.lower().str.strip()\n",
    "\n",
    "# CRITICAL FIX: Ensure no row is purely empty or just whitespace\n",
    "# This prevents the 'Empty Vocabulary' error in TfidfVectorizer\n",
    "games['features'] = games['features'].replace('', 'steam game indie casual')\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL BUILDING (TF-IDF & COSINE SIMILARITY)\n",
    "# ==========================================\n",
    "print(\"Step 3: Vectorizing and Calculating Similarity...\")\n",
    "\n",
    "# Use a custom token_pattern to catch words of at least 1 character (Fixes ValueError)\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    max_features=5000,\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\" \n",
    ")\n",
    "\n",
    "try:\n",
    "    tfidf_matrix = tfidf.fit_transform(games['features'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    print(\"Success! Similarity matrix created.\")\n",
    "except ValueError:\n",
    "    # Final fallback if TF-IDF still struggles with stop words\n",
    "    tfidf = TfidfVectorizer(stop_words=None, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "    tfidf_matrix = tfidf.fit_transform(games['features'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    print(\"Success! Similarity matrix created using fallback settings.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. RECOMMENDATION LOGIC & TESTING\n",
    "# ==========================================\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    try:\n",
    "        # Find index of the game (case-insensitive search)\n",
    "        idx = games[games['title'].str.contains(re.escape(title), case=False, na=False)].index[0]\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get top 5 recommendations (skipping the first one as it's the input game)\n",
    "        sim_scores = sim_scores[1:6]\n",
    "        game_indices = [i[0] for i in sim_scores]\n",
    "        \n",
    "        return games.iloc[game_indices][['title', genre_col if genre_col else 'features']]\n",
    "    except Exception as e:\n",
    "        return f\"Could not find recommendations for '{title}'. Try another game.\"\n",
    "\n",
    "# Test with the first game in the list\n",
    "test_game = games['title'].iloc[0]\n",
    "print(f\"\\nTesting recommendations for: {test_game}\")\n",
    "print(get_recommendations(test_game))\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXPORT FOR STREAMLIT WEB GUI\n",
    "# ==========================================\n",
    "print(\"\\nStep 4: Saving pkl files for app.py...\")\n",
    "# We save the dataframe and the similarity matrix to load them into Streamlit\n",
    "joblib.dump(cosine_sim, 'similarity_model.pkl')\n",
    "joblib.dump(games, 'games_data.pkl')\n",
    "\n",
    "print(\"All set! 'similarity_model.pkl' and 'games_data.pkl' are in your folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82a137-1401-48ab-82ca-231b2f740f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
